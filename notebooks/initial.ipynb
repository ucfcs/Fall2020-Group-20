{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using sc2reader to load a replay into a Python object\n",
    "1. Examining some of the basic replay information in the result\n",
    "1. Parsing the contest details into a usable object\n",
    "1. Visualizing the contest with graphics\n",
    "1. Storing the processed replay in Cloudant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_version = '3.7.7'\n",
    "pythons = ['python','python3']\n",
    "\n",
    "found_python = False\n",
    "for python in pythons:\n",
    "    p = !{python} -V\n",
    "    if working_version in p[0]:\n",
    "        found_python = True\n",
    "        print('You\\'re using Python %s with the alias %s.' % (working_version, python))\n",
    "\n",
    "if not found_python:\n",
    "    raise Exception('Unable to find Python %s in your environment.' % working_version)"
   ]
  },
  {
   "source": [
    "## Setup prerequisites\n",
    "### Install the _sc2reader_, _cloudant_ and _bokeh_ Python packages from PyPI\n",
    "\n",
    "* **_sc2reader_** is an open source library for processing StarCraft 2 replay files.\n",
    "* **_cloudant_** is the Python client for using the Cloudant NoSQL DB.\n",
    "* **_bokeh_** is a Python interactive visualization library.\n",
    "* **_seaborn_** is a Python data visualization library based on matplotlib.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dependencies = 'bokeh sc2reader s2protocol pandas seaborn matplotlib numpy'\n",
    "split_ds = dependencies.split(' ')\n",
    "pips = ['pip','pip3']\n",
    "\n",
    "found_pip = False\n",
    "\n",
    "for pip in pips:\n",
    "    p = !{pip}\n",
    "    if 'not found' not in p[0]:\n",
    "        found_pip = True\n",
    "        pip_list = !{pip} 'list'\n",
    "        flat_pip_list = ' '.join(pip_list)\n",
    "\n",
    "        if any(word+' ' not in flat_pip_list for word in split_ds):\n",
    "            !{pip} install {dependencies}\n",
    "        else:\n",
    "            print('You have all the necessary dependencies installed.')\n",
    "\n",
    "if not found_pip:\n",
    "    raise Exception('Unable to find pip or pip3. How are you even running this?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import glob\n",
    "# from sys import platform\n",
    "\n",
    "# paths = None\n",
    "# if platform == 'darwin':\n",
    "#     paths = [path for path in glob.glob('/Applications/StarCraft II/Replays/*.SC2Replay', recursive=True)]\n",
    "# elif platform in ['win32','win64']:\n",
    "#     paths = [path for path in glob.glob('/Applications/StarCraft II/Replays/*.SC2Replay', recursive=True)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Replay successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sc2reader\n",
    "from sc2reader.engine.plugins import APMTracker, ContextLoader, SelectionTracker\n",
    "from sc2reader.events import PlayerStatsEvent, UnitBornEvent, UnitDiedEvent, UnitDoneEvent, UnitTypeChangeEvent, UpgradeCompleteEvent\n",
    "import glob\n",
    "\n",
    "paths = [path for path in glob.glob('./_data/**/*.SC2Replay', recursive=True)]\n",
    "# paths = [path for path in glob.glob('/Applications/StarCraft II/Replays/*.SC2Replay', recursive=True)]\n",
    "\n",
    "replay_file = './king_sejong_station_le.sc2replay'\n",
    "replay_file = paths[1]\n",
    "\n",
    "replay = sc2reader.load_replay(\n",
    "    replay_file,\n",
    "    engine=sc2reader.engine.GameEngine(plugins=[ContextLoader(), APMTracker(), SelectionTracker()]))\n",
    "\n",
    "print('Replay successfully loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the replay\n",
    "\n",
    "Load in the replay with sc2reader. We'll use bytes that the inserted code read from our\n",
    "IBM Cloud Object Storage container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date: 2020-08-30 12:27:01\nMap Name: Submarine LE\nLoss: Player 1 - Seither (Terran)\nWin: Player 2 - Probe (Protoss)\n"
     ]
    }
   ],
   "source": [
    "print(\"Date: %s\" % replay.date)\n",
    "print(\"Map Name: \" + replay.map_name)\n",
    "for player in replay.players:\n",
    "    print(\"%s: %s\" % (player.result, player))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print basic replay information\n",
    "\n",
    "With the replay added, we can now inspect the object in the notebook. We can easily get information\n",
    "like date, map name, participants, winner/loser, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['vespene_units', 'supply_units', 'worker_units', 'base_units', 'ground_units', 'air_units', 'tech_units', 'army_units', 'army_air', 'army_ground'])"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pieces.pickle', 'rb') as f:\n",
    "    pieces = pickle.load(f)\n",
    "\n",
    "pieces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish our event parsers\n",
    "\n",
    "def handle_count(caller, event, key, add_value, start_val=0):\n",
    "    if len(caller.players[event.unit.owner.pid][key]) == 0:\n",
    "        caller.players[event.unit.owner.pid][key].append((0, 0))\n",
    "    # Get the last value\n",
    "    last_val = caller.players[event.unit.owner.pid][key][-1][1]\n",
    "    caller.players[event.unit.owner.pid][key].append((event.frame, last_val + add_value))\n",
    "\n",
    "\n",
    "def handle_expansion_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['base_units']:\n",
    "            caller.players[event.unit.owner.pid][\"expansion_event\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, \"expansion_buildings\", 1, start_val=1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['base_units']:\n",
    "            caller.players[event.unit.owner.pid][\"expansion_event\"].append((event.frame, \"-\", unit))\n",
    "            handle_count(caller, event, \"expansion_buildings\", -1, start_val=1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit.name in pieces['base_units']:\n",
    "            caller.players[event.unit.owner.pid][\"expansion_event\"].append((event.frame, \"*\", event.unit.name))\n",
    "\n",
    "\n",
    "def handle_worker_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"workers_active\"].append((event.frame, event.workers_active_count))\n",
    "    elif type(event) is UnitBornEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['worker_units']:\n",
    "            caller.players[event.control_pid][\"worker_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['worker_units']:\n",
    "            caller.players[event.unit.owner.pid][\"worker_event\"].append((event.frame, \"-\", unit))\n",
    "\n",
    "\n",
    "def handle_supply_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"supply_available\"].append((event.frame, int(event.food_made)))\n",
    "        caller.players[event.pid][\"supply_consumed\"].append((event.frame, int(event.food_used)))\n",
    "        utilization = 0 if event.food_made == 0 else event.food_used / event.food_made\n",
    "        caller.players[event.pid][\"supply_utilization\"].append((event.frame, utilization))\n",
    "        worker_ratio = 0 if event.food_used == 0 else event.workers_active_count / event.food_used\n",
    "        caller.players[event.pid][\"worker_supply_ratio\"].append((event.frame, worker_ratio))\n",
    "    elif type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['supply_units']:\n",
    "            caller.players[event.unit.owner.pid][\"supply_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitBornEvent:\n",
    "        # Specifically for Overlord\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit == \"Overlord\":\n",
    "            caller.players[event.control_pid][\"supply_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        # Buildings/ Overlord/Overseer\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['supply_units']:\n",
    "            caller.players[event.unit.owner.pid][\"supply_event\"].append((event.frame, \"-\", unit))\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name == \"Overseer\":\n",
    "            caller.players[event.unit.owner.pid][\"supply_event\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "\n",
    "\n",
    "def handle_vespene_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"vespene_available\"].append((event.frame, event.vespene_current))\n",
    "        caller.players[event.pid][\"vespene_collection_rate\"].append((event.frame, event.vespene_collection_rate))\n",
    "        vesp_per_worker = 0 if event.workers_active_count == 0 else event.vespene_collection_rate / event.workers_active_count\n",
    "        caller.players[event.pid][\"vespene_per_worker_rate\"].append((event.frame, vesp_per_worker))\n",
    "        caller.players[event.pid][\"vespene_cost_active_forces\"].append((event.frame, event.vespene_used_active_forces))\n",
    "        caller.players[event.pid][\"vespene_spend\"].append((event.frame, event.vespene_used_current))\n",
    "        caller.players[event.pid][\"vespene_value_current_technology\"].append((event.frame, event.vespene_used_current_technology))\n",
    "        caller.players[event.pid][\"vespene_value_current_army\"].append((event.frame, event.vespene_used_current_army))\n",
    "        caller.players[event.pid][\"vespene_value_current_economic\"].append((event.frame, event.vespene_used_current_economy))\n",
    "        caller.players[event.pid][\"vespene_queued\"].append((event.frame, event.vespene_used_in_progress))\n",
    "        caller.players[event.pid][\"vespene_queued_technology\"].append((event.frame, event.vespene_used_in_progress_technology))\n",
    "        caller.players[event.pid][\"vespene_queued_army\"].append((event.frame, event.vespene_used_in_progress_technology))\n",
    "        caller.players[event.pid][\"vespene_queued_economic\"].append((event.frame, event.vespene_used_in_progress_economy))\n",
    "    elif type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['vespene_units']:\n",
    "            caller.players[event.unit.owner.pid][\"vespene_event\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['vespene_units']:\n",
    "            caller.players[event.unit.owner.pid][\"vespene_event\"].append((event.frame, \"-\", unit))\n",
    "\n",
    "\n",
    "def handle_resources_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"mineral_destruction\"].append((event.frame, event.minerals_killed))\n",
    "        caller.players[event.pid][\"mineral_destruction_army\"].append((event.frame, event.minerals_killed_army))\n",
    "        caller.players[event.pid][\"mineral_destruction_economic\"].append((event.frame, event.minerals_killed_economy))\n",
    "        caller.players[event.pid][\"mineral_destruction_technology\"].append((event.frame, event.minerals_killed_technology))\n",
    "        caller.players[event.pid][\"mineral_loss\"].append((event.frame, event.minerals_lost))\n",
    "        caller.players[event.pid][\"mineral_loss_army\"].append((event.frame, event.minerals_lost_army))\n",
    "        caller.players[event.pid][\"mineral_loss_economic\"].append((event.frame, event.minerals_lost_economy))\n",
    "        caller.players[event.pid][\"mineral_loss_technology\"].append((event.frame, event.minerals_lost_technology))\n",
    "\n",
    "        caller.players[event.pid][\"vespene_destruction\"].append((event.frame, event.vespene_killed))\n",
    "        caller.players[event.pid][\"vespene_destruction_army\"].append((event.frame, event.vespene_killed_army))\n",
    "        caller.players[event.pid][\"vespene_destruction_economic\"].append((event.frame, event.vespene_killed_economy))\n",
    "        caller.players[event.pid][\"vespene_destruction_technology\"].append((event.frame, event.vespene_killed_technology))\n",
    "        caller.players[event.pid][\"vespene_loss\"].append((event.frame, event.vespene_lost))\n",
    "        caller.players[event.pid][\"vespene_loss_army\"].append((event.frame, event.vespene_lost_army))\n",
    "        caller.players[event.pid][\"vespene_loss_economic\"].append((event.frame, event.vespene_lost_economy))\n",
    "        caller.players[event.pid][\"vespene_loss_technology\"].append((event.frame, event.vespene_lost_technology))\n",
    "\n",
    "\n",
    "def handle_ground_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['ground_units']:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"ground_building\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['ground_units']:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"ground_building\"].append((event.frame, \"-\", unit))\n",
    "            handle_count(caller, event, count_name, -1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name == \"LurkerDen\":\n",
    "            count_name = \"_\".join([\"building\", event.unit_type_name, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"ground_building\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "\n",
    "\n",
    "def handle_air_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['air_units']:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"air_building\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['air_units']:\n",
    "            count_name = \"_\".join([\"building\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"air_building\"].append((event.frame, \"-\", unit))\n",
    "            handle_count(caller, event, count_name, -1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name == \"GreaterSpire\":\n",
    "            count_name = \"_\".join([\"building\", event.unit_type_name, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"air_building\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "            handle_count(caller, event, count_name, 1)\n",
    "\n",
    "\n",
    "def handle_unit_events(caller, event):\n",
    "    if type(event) is UnitBornEvent:\n",
    "        unit = event.unit_type_name\n",
    "        if unit in pieces['army_units']:\n",
    "            unit_count_name = \"_\".join([\"unit\", unit, \"count\"])\n",
    "            caller.players[event.control_pid][\"army_event\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, unit_count_name, 1)\n",
    "            if unit in pieces['army_air']:\n",
    "                handle_count(caller, event, \"army_air\", 1)\n",
    "            elif unit in pieces['army_ground']:\n",
    "                handle_count(caller, event, \"army_ground\", 1)\n",
    "            handle_count(caller, event, \"army_count\", 1)\n",
    "    elif type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['army_units']:\n",
    "            unit_count_name = \"_\".join([\"unit\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"army_event\"].append((event.frame, \"+\", unit))\n",
    "            handle_count(caller, event, unit_count_name, 1)\n",
    "            if unit in pieces['army_air']:\n",
    "                handle_count(caller, event, \"army_air\", 1)\n",
    "            elif unit in pieces['army_ground']:\n",
    "                handle_count(caller, event, \"army_air\", 1)\n",
    "            handle_count(caller, event, \"army_count\", 1)\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['army_units']:\n",
    "            unit_count_name = \"_\".join([\"unit\", unit, \"count\"])\n",
    "            caller.players[event.unit.owner.pid][\"army_event\"].append((event.frame, \"-\", unit))\n",
    "            if unit in pieces['army_air']:\n",
    "                handle_count(caller, event, \"army_air\", -1)\n",
    "            elif unit in pieces['army_ground']:\n",
    "                handle_count(caller, event, \"army_ground\", -1)\n",
    "            handle_count(caller, event, unit_count_name, -1)\n",
    "            handle_count(caller, event, \"army_count\", -1)\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if event.unit_type_name in pieces['army_units']:\n",
    "            unit_count_name = \"_\".join([\"unit\", event.unit_type_name, \"count\"])\n",
    "\n",
    "            caller.players[event.unit.owner.pid][\"army_event\"].append((event.frame, \"*\", unit))\n",
    "\n",
    "            handle_count(caller, event, unit_count_name, 1)\n",
    "\n",
    "\n",
    "def handle_tech_events(caller, event):\n",
    "    if type(event) is UnitDoneEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['tech_units']:\n",
    "            caller.players[event.unit.owner.pid][\"tech_building\"].append((event.frame, \"+\", unit))\n",
    "    elif type(event) is UnitDiedEvent:\n",
    "        unit = str(event.unit).split()[0]\n",
    "        if unit in pieces['tech_units']:\n",
    "            caller.players[event.unit.owner.pid][\"tech_building\"].append((event.frame, \"-\", unit))\n",
    "    elif type(event) is UnitTypeChangeEvent:\n",
    "        if event.unit_type_name in [\"GreaterSpire\", \"LurkerDen\"]:\n",
    "            caller.players[event.unit.owner.pid][\"tech_building\"].append((event.frame, \"*\", event.unit_type_name))\n",
    "\n",
    "\n",
    "def handle_upgrade_events(caller, event):\n",
    "    if type(event) is UpgradeCompleteEvent and event.frame > 0:\n",
    "        if not event.upgrade_type_name.startswith(\"Spray\"):\n",
    "            caller.players[event.pid][\"upgrades\"].append((event.frame, event.upgrade_type_name))\n",
    "\n",
    "\n",
    "def handle_mineral_events(caller, event):\n",
    "    if type(event) is PlayerStatsEvent:\n",
    "        caller.players[event.pid][\"minerals_available\"].append((event.frame, event.minerals_current))\n",
    "        caller.players[event.pid][\"mineral_collection_rate\"].append((event.frame, event.minerals_collection_rate,))\n",
    "        caller.players[event.pid][\"mineral_cost_active_forces\"].append((event.frame, event.minerals_used_active_forces))\n",
    "        mins_per_worker = 0 if event.workers_active_count == 0 else event.minerals_collection_rate / event.workers_active_count\n",
    "        caller.players[event.pid][\"mineral_per_worker_rate\"].append((event.frame, mins_per_worker))\n",
    "        caller.players[event.pid][\"mineral_spend\"].append((event.frame, event.minerals_used_current))\n",
    "        caller.players[event.pid][\"mineral_value_current_technology\"].append((event.frame, event.minerals_used_current_technology))\n",
    "        caller.players[event.pid][\"mineral_value_current_army\"].append((event.frame, event.minerals_used_current_army))\n",
    "        caller.players[event.pid][\"mineral_value_current_economic\"].append((event.frame, event.minerals_used_current_economy))\n",
    "        caller.players[event.pid][\"mineral_queued\"].append((event.frame, event.minerals_used_in_progress))\n",
    "        caller.players[event.pid][\"mineral_queued_technology\"].append((event.frame, event.minerals_used_in_progress_technology))\n",
    "        caller.players[event.pid][\"mineral_queued_army\"].append((event.frame, event.minerals_used_in_progress_army))\n",
    "        caller.players[event.pid][\"mineral_queued_economic\"].append((event.frame, event.minerals_used_in_progress_economy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all of our event parsers for use by our ReplayData class\n",
    "\n",
    "handlers = [handle_expansion_events, handle_worker_events, handle_supply_events, handle_mineral_events,\n",
    "            handle_vespene_events, handle_ground_events, handle_air_events, handle_tech_events, handle_upgrade_events,\n",
    "            handle_unit_events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we define our class ReplayData for helping us structure and process our replay files\n",
    "\n",
    "class ReplayData:\n",
    "    __parsers__ = handlers\n",
    "\n",
    "    @classmethod\n",
    "    def parse_replay(cls, replay=None, replay_file=None, file_object=None):\n",
    "        \n",
    "        replay_data = ReplayData(replay_file)\n",
    "        try:\n",
    "            # This is the engine that holds some required plugins for parsing\n",
    "            engine = sc2reader.engine.GameEngine(plugins=[ContextLoader(), APMTracker(), SelectionTracker()])\n",
    "               \n",
    "            if replay:\n",
    "                pass\n",
    "            elif replay_file and not file_object:\n",
    "                # Then we are not using ObjectStorage for accessing replay files\n",
    "                replay = sc2reader.load_replay(replay_file, engine=engine)\n",
    "            elif file_object:\n",
    "                # We are using ObjectStorage to access replay files\n",
    "                replay = sc2reader.load_replay(file_object, engine=engine)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # Get the number of frames (one frame is 1/16 of a second)\n",
    "            replay_data.frames = replay.frames\n",
    "            # Gets the game mode (if available)\n",
    "            replay_data.game_mode = replay.real_type\n",
    "            # Gets the map hash (if we want to download the map, or do map-based analysis)\n",
    "            replay_data.map_hash = replay.map_hash\n",
    "            \n",
    "            # Use the parsers to get data\n",
    "            for event in replay.events:\n",
    "                for parser in cls.__parsers__:\n",
    "                    parser(replay_data, event)\n",
    "            \n",
    "            # Check if there was a winner\n",
    "            if replay.winner is not None:\n",
    "                replay_data.winners = replay.winner.players\n",
    "                replay_data.losers = [p for p in replay.players if p not in replay.winner.players]\n",
    "            else:\n",
    "                replay_data.winners = []\n",
    "                replay_data.losers = []\n",
    "            # Check to see if expansion data is available\n",
    "            replay_data.expansion = replay.expansion\n",
    "            return replay_data\n",
    "        except:\n",
    "            # print our error and return NoneType object\n",
    "            print_exc()\n",
    "            return None\n",
    "        \n",
    "    def as_dict(self):\n",
    "        return {\n",
    "            \"processed_on\": datetime.utcnow().isoformat(),\n",
    "            \"replay_name\": self.replay,\n",
    "            \"expansion\": self.expansion,\n",
    "            \"frames\": self.frames,\n",
    "            \"mode\": self.game_mode,\n",
    "            \"map\": self.map_hash,\n",
    "            \"matchup\": \"v\".join(sorted([s.detail_data[\"race\"][0].upper() for s in self.winners + self.losers])),\n",
    "            \"winners\": [(s.pid, s.name, s.detail_data['race']) for s in self.winners],\n",
    "            \"losers\": [(s.pid, s.name, s.detail_data['race']) for s in self.losers],\n",
    "            \"stats_names\": [k for k in self.players[1].keys()],\n",
    "            \"stats\": {player: data for player, data in self.players.items()}\n",
    "        }\n",
    "\n",
    "    def __init__(self, replay):\n",
    "        self.players = defaultdict(lambda: defaultdict(list))\n",
    "        self.replay = replay\n",
    "        self.winners = []\n",
    "        self.losers = []\n",
    "        self.expansion = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and compare replay events\n",
    "\n",
    "The replay file was processed to add event statistics using pandas and\n",
    "helper functions.\n",
    "* Bokeh is used to create Nelson rules charts.\n",
    "* Seaborn is used for box plot charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "\n    <div class=\"bk-root\">\n        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n        <span id=\"1001\">Loading BokehJS ...</span>\n    </div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from traceback import print_exc\n",
    "\n",
    "from bokeh.io import output_notebook, reset_output\n",
    "from bokeh.models import Span, Range1d, Legend, BoxAnnotation, HoverTool, Arrow, NormalHead\n",
    "from bokeh.plotting import figure, show, gridplot, ColumnDataSource\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(i, last_entry, sign=None, length=3):\n",
    "    if last_entry is not None:\n",
    "        if sign is not None:\n",
    "            # Check to see if this is a continuation\n",
    "            if last_entry[1] == i + length - 1 and last_entry[2] == sign:\n",
    "                return [(last_entry[0], i + length, sign)]\n",
    "            else:\n",
    "                return [last_entry, (i, i + length, sign)]\n",
    "        else:\n",
    "            # Check to see if this is a continuation\n",
    "            if last_entry[1] == i + length - 1:\n",
    "                return [(last_entry[0], i + length)]\n",
    "            else:\n",
    "                return [last_entry, (i, i + length)]\n",
    "    else:\n",
    "        if sign is not None:\n",
    "            return [(i, i + length, sign)]\n",
    "        else:\n",
    "            return [(i, i + length)]\n",
    "                \n",
    "\n",
    "                \n",
    "def detect_nelson_bias(src_data, x_bar):\n",
    "    # Bias is defined as 9 or more consecutive points sitting above or below our x-bar line\n",
    "    bias_ranges = []\n",
    "    length = 9\n",
    "    for i in range(len(src_data) - length):\n",
    "        last_entry = bias_ranges.pop() if len(bias_ranges) > 0 else None\n",
    "        if all([src_data[k] > x_bar for k in range(i, i + length)]):\n",
    "            sign = \"+\"\n",
    "            bias = merge(i, last_entry, sign=sign, length=length)\n",
    "            bias_ranges.extend(bias)\n",
    "        elif all([src_data[k] < x_bar for k in range(i, i+length)]):\n",
    "            sign = \"-\"\n",
    "            bias = merge(i, last_entry, sign=sign, length=length)\n",
    "            bias_ranges.extend(bias)\n",
    "        else:\n",
    "            if last_entry:\n",
    "                bias_ranges.append(last_entry)\n",
    "                \n",
    "    return bias_ranges\n",
    "\n",
    "def detect_nelson_trend(src_data, std):\n",
    "    # Trend is defined as 6 or more consecutive points all increasing or decreasing (or 6 or more consecutive non(increasing, decreasing) where difference between start and end points greater than 1.5 standard deviations )\n",
    "    trend_ranges = []\n",
    "    length = 6\n",
    "    for i in range(len(src_data) - length):\n",
    "        last_entry = trend_ranges.pop() if len(trend_ranges) > 0 else None\n",
    "        if (all(x<y for x, y in zip(src_data[i:i+length], src_data[i+1:i+length]))\n",
    "            or (all(x<=y for x,y in zip(src_data[i:i+length], src_data[i+1:i+length])) \n",
    "                and abs(src_data[i] - src_data[i+length]) >= 1.5*std)):\n",
    "            sign = \"+\"\n",
    "            trend_ranges.extend(merge(i, last_entry, sign=sign, length=length))\n",
    "        elif (all(x>y for x, y in zip(src_data[i:i+length], src_data[i+1:i+length])) \n",
    "            or (all(x>=y for x,y in zip(src_data[i:i+length], src_data[i+1:i+length]))\n",
    "                and abs(src_data[i] - src_data[i+length]) >= 1.5*std)):\n",
    "            sign = \"-\"\n",
    "            trend_ranges.extend(merge(i, last_entry, sign=sign, length=length))\n",
    "        else:\n",
    "            if last_entry:\n",
    "                trend_ranges.append(last_entry)\n",
    "    \n",
    "    return trend_ranges\n",
    "            \n",
    "def detect_nelson_oscillation(src_data):\n",
    "    # Oscillation is defined as 14 or more consecutive points, all alternating in direction\n",
    "    diff = lambda x, y: 1 if y - x > 0 else -1 if y - x  < 0 else None\n",
    "    oscillation_ranges = []\n",
    "    length=14\n",
    "    deltas = []\n",
    "    for i in range(len(src_data) - length):\n",
    "        last_entry = oscillation_ranges.pop() if len(oscillation_ranges) > 0 else None\n",
    "        sign = None\n",
    "        is_oscillating = True\n",
    "        for curr in range(i, i + length - 1):\n",
    "            if sign == None and curr == i:\n",
    "                sign = diff(src_data[curr], src_data[curr + 1])\n",
    "            elif sign is None and curr != i:\n",
    "                is_oscillating = False\n",
    "                break\n",
    "            else:\n",
    "                new_sign = diff(src_data[curr], src_data[curr + 1])\n",
    "                if new_sign is None or new_sign == sign:\n",
    "                    is_oscillating = False\n",
    "                    break\n",
    "                elif new_sign != sign and new_sign is not None:\n",
    "                    sign = new_sign\n",
    "        if is_oscillating:\n",
    "            # check if this is a continuation of a previous oscillation\n",
    "            oscillation_ranges.extend(merge(i, last_entry, length=length))\n",
    "            \n",
    "        else:\n",
    "            if last_entry:\n",
    "                oscillation_ranges.append(last_entry)\n",
    "    \n",
    "    return oscillation_ranges\n",
    "\n",
    "\n",
    "def avg_last_minute(process, pid, time, replay):\n",
    "    data = pd.DataFrame({\n",
    "            \"Data\": [k[1] for k in replay.stats[pid-1][process]]},\n",
    "            index=[int(k[0]/16) for k in replay.stats[pid - 1][process]])\n",
    "    \n",
    "    rolling = data.rolling(6).mean()\n",
    "    pct_change = data.pct_change()\n",
    "    ndx = data.index.get_loc(time, method=\"ffill\")\n",
    "\n",
    "    prev_ndx = max(ndx - 1, 0)\n",
    "    print(ndx, prev_ndx)\n",
    "    r_mean = rolling.get_value(rolling.index[ndx], \"Data\")\n",
    "    prev_mean = rolling.get_value(rolling.index[prev_ndx], \"Data\")\n",
    "    print(r_mean, prev_mean)\n",
    "    print(pct_change)\n",
    "    pcng = pct_change.get_value(rolling.index[ndx], \"Data\")\n",
    "\n",
    "    change = \"\" if r_mean > prev_mean else \"\" if r_mean < prev_mean else \"\"\n",
    "    \n",
    "    return r_mean if not pd.isnull(r_mean) else 0, change, pcng if not (pd.isnull(pcng) or pcng != np.Inf) else 0\n",
    "    \n",
    "\n",
    "# Define Nelson Rules Chart Generator\n",
    "def nelson_rules_chart_generator(src, timeseries, player, pid, process_name, unit_name, replay, plot_width=350,fill_color=\"blue\", line_color=\"blue\", line_width=2, annotations=None, fixed_lcl=None, fixed_ucl=None):\n",
    "    # We strip the first two data points (first data point is 0 and second data point should roughly be the same for all games)\n",
    "    x_bar = src[2:].mean()\n",
    "    std = src[2:].std()\n",
    "    ctrl_limits = [x_bar + (k*std) for k in range(-3, 4)]\n",
    "    ctrl_labels = [\"LCL\", \"-2\", \"-1\", \"x-bar\", \"1\", \"2\", \"UCL\"]\n",
    "    ctrl_colors = [\"#55597F\", \"#5D6DFF\",\"#A9B2FF\",\"#000000\", \"#FF9E9F\", \"#FF5253\",\"#7F2929\"]\n",
    "    ctrl_dash = [\"solid\", \"dashed\", \"dashed\", \"solid\", \"dashed\", \"dashed\", \"solid\"]\n",
    "    ctrl_legend = [\"{0} - {1:10.4f}\".format(cl[0], cl[1]) for cl in zip(ctrl_labels, ctrl_limits)]\n",
    "    ctrl_width = [3, 2, 2, 3, 2, 2, 3]\n",
    "    \n",
    "    \n",
    "    significant = lambda x: x > ctrl_limits[5] or x < ctrl_limits[1]\n",
    "    \n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"time\", \"@x\"),\n",
    "            (\"value\", \"@y\")\n",
    "        ])\n",
    "    \n",
    "    p = figure(plot_width=plot_width, plot_height=300, x_axis_label=\"Game Time (in seconds)\", y_axis_label=unit_name, tools=[hover], toolbar_location=\"above\")\n",
    "    # Generate control lines\n",
    "    lines = []\n",
    "    source = ColumnDataSource(data=dict(x=[x/16 for x in timeseries], \n",
    "                                        y=src,\n",
    "                                        alpha=[1 if significant(y) and ndx > 2 else 0.7 for ndx, y in enumerate(src)], \n",
    "                                        radius=[6 if significant(y) and ndx > 2 else 4 for ndx, y in enumerate(src)], \n",
    "                                        ))\n",
    "    for ndx, cl in enumerate(ctrl_limits):\n",
    "        limit = cl\n",
    "            \n",
    "        lines.append(p.line([x/16 for x in timeseries], \n",
    "                            [limit]*len(timeseries), \n",
    "                            line_width=ctrl_width[ndx], \n",
    "                            line_dash=ctrl_dash[ndx], \n",
    "                            tags=[ctrl_labels[ndx] if k == 0 else None for k, _ in enumerate(timeseries)],  \n",
    "                            line_color=ctrl_colors[ndx]))\n",
    "        \n",
    "    \n",
    "    p.circle(\"x\", \"y\",\n",
    "             source=source,\n",
    "             alpha=\"alpha\", \n",
    "             radius=\"radius\", \n",
    "             fill_color=fill_color,  \n",
    "             line_width=line_width)\n",
    "    \n",
    "    \n",
    "    # Handle bias\n",
    "    bias_ranges = detect_nelson_bias(src, x_bar)\n",
    "    for rng in bias_ranges:\n",
    "        if rng[2] is \"+\":\n",
    "            p.add_layout(BoxAnnotation(bottom=x_bar, top=ctrl_limits[-1], left=timeseries[rng[0]]/16, right=timeseries[rng[1]]/16, fill_color=\"green\"))\n",
    "        elif rng[2] is \"-\":\n",
    "            p.add_layout(BoxAnnotation(top=x_bar, bottom=ctrl_limits[0], left=timeseries[rng[0]]/16, right=timeseries[rng[1]]/16, fill_color=\"red\"))\n",
    "            \n",
    "    # Handle trends\n",
    "    trend_ranges = detect_nelson_trend(src, std)\n",
    "    for rng in trend_ranges:\n",
    "        if rng[2] is \"+\":\n",
    "            p.add_layout(Arrow(end=NormalHead(line_color=\"goldenrod\",\n",
    "                                              fill_color=\"goldenrod\"),\n",
    "                               x_start=timeseries[rng[0]]/16,\n",
    "                               y_start=src[rng[0]],\n",
    "                               x_end=timeseries[rng[1]]/16,\n",
    "                               y_end=src[rng[1]],\n",
    "                               line_width=4,\n",
    "                               line_alpha=0.6,\n",
    "                               line_dash=\"solid\"))\n",
    "        elif rng[2] is \"-\":\n",
    "            p.add_layout(Arrow(end=NormalHead(line_color=\"#7F0000\",\n",
    "                                              fill_color=\"#7F0000\"),\n",
    "                               x_start=timeseries[rng[0]]/16,\n",
    "                               y_start=src[rng[0]],\n",
    "                               x_end=timeseries[rng[1]]/16,\n",
    "                               y_end=src[rng[1]],\n",
    "                               line_width=4,\n",
    "                               line_alpha=0.6,\n",
    "                               line_dash=\"solid\"))\n",
    "    \n",
    "    p.title.text = \"{0} for {1}\".format(unit_name, player)\n",
    "    p.y_range = p.y_range = Range1d(ctrl_limits[0] - 0.125 * ctrl_limits[0],  1.125 * ctrl_limits[-1])\n",
    "    \n",
    "    legend = Legend(items=list(zip(ctrl_legend, [[l] for l in lines])), location=(10,-30))\n",
    "    p.add_layout(legend, \"right\")\n",
    "    \n",
    "    return p, ctrl_limits, min(src[2:]), max(src[2:]), timeseries[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_object = ReplayData.parse_replay(replay=replay)\n",
    "replay_dict = replay_object.as_dict()\n",
    "\n",
    "players = {}\n",
    "for player in replay_dict[\"winners\"]:\n",
    "    players[int(player[0])] = {\"full\": \"Winning Player {num}: {name} ({race})\".format(num=player[0], name=player[1], race=player[2]),\n",
    "                               \"short\": \"{name} ({race})\".format(name=player[1], race=player[2]) }\n",
    "for player in replay_dict[\"losers\"]:\n",
    "    players[int(player[0])] = {\"full\": \"Losing Player {num}: {name} ({race})\".format(num=player[0], name=player[1], race=player[2]),\n",
    "                               \"short\": \"{name} ({race})\".format(name=player[1], race=player[2]) }\n",
    "\n",
    "econ = [\"mineral_collection_rate\", \"vespene_collection_rate\", \"workers_active\", \"supply_utilization\", \"worker_supply_ratio\"]\n",
    "units = [\"Minerals per Minute (MPM)\", \"Vespene per Minute (VPM)\", \"Workers\", \"Supply Used / Supply Available\", \"Workers / Supply Used\"]\n",
    "\n",
    "player_charts = defaultdict(dict)\n",
    "player_aggregate = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pid, player in players.items():\n",
    "    for ndx, process in enumerate(econ):\n",
    "        # Generate charts per player\n",
    "        timeseries = [k[0] for k in replay_dict[\"stats\"][pid][process]]\n",
    "        proc_data = [j[1] for j in replay_dict[\"stats\"][pid][process]]\n",
    "\n",
    "        player_charts[pid][process], limits, v_min, v_max, game_length = nelson_rules_chart_generator(\n",
    "            pd.Series(proc_data),\n",
    "            timeseries,\n",
    "            player[\"full\"],\n",
    "            pid,\n",
    "            process,\n",
    "            units[ndx],\n",
    "            replay,\n",
    "            fixed_lcl=0)\n",
    "        player_aggregate[process][pid] = proc_data\n",
    "\n",
    "grid = [[player_charts[k][measurement] for k in player_charts] for ndx, measurement in enumerate(econ)]\n",
    "\n",
    "show(gridplot(grid, sizing_mode=\"scale_width\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(grid),ncols=1,figsize=(15,20))\n",
    "\n",
    "for ndx in range(len(grid)):\n",
    "\n",
    "    sample_max = min([len(player_aggregate[econ[ndx]][j]) for j in player_aggregate[econ[ndx]].keys()])\n",
    "    # Remember, we are removing the first 20 samples (beginning of game should be the same for all, so data is useless)\n",
    "    frame = pd.DataFrame({ units[ndx]: [player_aggregate[econ[ndx]][1][k] for k in range(2,sample_max)] + [player_aggregate[econ[ndx]][2][l] for l in range(2,sample_max)],\n",
    "                           \"Player\": [players[(i//sample_max) + 1][\"short\"] for i in range(0,len(players.keys())*(sample_max - 2))]})\n",
    "    \n",
    "    bp = seaborn.boxplot(x=units[ndx], orient=\"h\", y='Player',  data=frame,  width=0.5, palette=\"muted\", ax=axes[ndx])\n",
    "    bp = seaborn.swarmplot(x=units[ndx], y='Player', data=frame,  color='gold', alpha=0.5, ax=axes[ndx])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Replay Files\n",
    "\n",
    "Now that we have loaded and processed the replay, we can store\n",
    "it for future use and aggregation.\n",
    "\n",
    "The replay_object has an as_dict() method to give us JSON.\n",
    "\n",
    "We'll store this in Cloudant for future use.\n",
    "\n",
    "1. Connect to Cloudant with our IBM Cloud credentials.\n",
    "2. Create 'sc2replays' and 'sc2recents' databases.\n",
    "3. Store the current replay as a document in the 'sc2replays' database.\n",
    "4. Store the current replay as a document in the 'sc2recents' database and remove the older replays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at what is in the object?\n",
    "# This creates a lot of output, but if you are curious just uncomment the following 2 lines:\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(replay_object.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cloudant.client import Cloudant\n",
    "\n",
    "# # Some extra code here helps catch setup errors.\n",
    "# try:\n",
    "#     sc2replay_creds = credentials_1\n",
    "#     print(\"Cloudant credentials added for storing replay data as JSON.\")\n",
    "# except NameError:\n",
    "#     print('\\n'\n",
    "#           'SETUP ERROR: Please follow the directions to add Cloudant credentials to the notebook.\\n'\n",
    "#           '             You may need jupyto rename the credentials_* variable.')\n",
    "#     raise\n",
    "\n",
    "# # Now we need to send this data to 2 databases \"sc2replays for aggregating, and sc2recents.\n",
    "\n",
    "# # Connect to cloudant service with IBM Cloud IAM credentials username and apikey.\n",
    "# esports = Cloudant.iam(sc2replay_creds[\"username\"], sc2replay_creds[\"apikey\"], connect=True)\n",
    "    \n",
    "# print(esports.all_dbs())\n",
    "# session = esports.session()\n",
    "\n",
    "# if 'sc2replays' not in esports.all_dbs():\n",
    "#         esports.create_database('sc2replays')\n",
    "        \n",
    "# sc2replays = esports['sc2replays']\n",
    "# document = sc2replays.create_document(replay_object.as_dict())\n",
    "# if document.exists():\n",
    "#     print(\"sc2replays entry saved. Latest id: {0}\".format(document[\"_id\"]))\n",
    "        \n",
    "# if 'sc2recents' not in esports.all_dbs():\n",
    "#     esports.create_database('sc2recents')\n",
    "        \n",
    "# sc2recents = esports['sc2recents']\n",
    "# # clear out everything in sc2recents db\n",
    "# for d in sc2recents:\n",
    "#     d.delete()\n",
    "        \n",
    "# document = sc2recents.create_document(replay_object.as_dict())\n",
    "# if document.exists():\n",
    "#     print(\"sc2recents entry saved. Latest id: {0}\".format(document[\"_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
    "not use this file except in compliance with the License. You may obtain\n",
    "a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    "WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    "License for the specific language governing permissions and limitations\n",
    "under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sc2reader\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from sc2reader.engine.plugins import APMTracker, ContextLoader, SelectionTracker\n",
    "from sc2reader.events import PlayerStatsEvent, UnitBornEvent, UnitDiedEvent, UnitDoneEvent, UnitTypeChangeEvent, UpgradeCompleteEvent\n",
    "import glob\n",
    "\n",
    "\n",
    "path = '/Applications/StarCraft II/Replays/'\n",
    "races = []\n",
    "\n",
    "winner = []\n",
    "loser = []\n",
    "\n",
    "# paths = [path for path in glob.glob('/Applications/StarCraft II/Replays/*.SC2Replay', recursive=True)]\n",
    "paths = [path for path in glob.glob('./folder/**/*.SC2Replay', recursive=True)]\n",
    "\n",
    "replays = []\n",
    "\n",
    "# number of replays to look into\n",
    "count = 10\n",
    "print('Found %d StarCraft II replays, but only loading %d replays.' % (len(paths), count))\n",
    "\n",
    "for i, path in enumerate(paths[:count]):\n",
    "    replay = sc2reader.load_replay(path, engine=sc2reader.engine.GameEngine(plugins=[ContextLoader(), APMTracker(), SelectionTracker()]))\n",
    "\n",
    "    races.append(replay.players[0].play_race[0])\n",
    "    replays.append(replay)\n",
    "    \n",
    "    print('\\r%6.2f%% complete' % ((i+1)/count*100), end='', flush=True)\n",
    "\n",
    "#     for player in replay.players:\n",
    "#         if player.result == 'Win':\n",
    "#             winner.append(player)\n",
    "#         else:\n",
    "#             loser.append(player)\n",
    "\n",
    "# print('\\n', races)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sc2reader\n",
    "from sc2reader.events import *\n",
    "\n",
    "replay = replays[0]\n",
    "\n",
    "lst = []\n",
    "\n",
    "for event in replay.player[1].events:\n",
    "    if isinstance(event, events.CameraEvent):  # Change of camera position    \n",
    "        try:\n",
    "            lst.append([event.pid, event.player, event.second, event.x, event.y, 'CameraEvent', event.frame])\n",
    "        except:\n",
    "            print('error')\n",
    "    elif isinstance(event, events.CommandEvent): # Player commands\n",
    "        try:\n",
    "            lst.append([event.pid, event.player, event.second, 'NA', 'NA', event.ability_type, event.frame])\n",
    "        except:\n",
    "            print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(lst, columns=['id', 'player', 'seconds', 'x', 'y', 'commandType', 'frame'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100.00% complete"
     ]
    }
   ],
   "source": [
    "import sc2reader\n",
    "from sc2reader.engine.plugins import APMTracker, ContextLoader, SelectionTracker\n",
    "from sc2reader import events\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "replays = []\n",
    "paths = [path for path in glob.glob('./_data/**/*.SC2Replay', recursive=True)]\n",
    "\n",
    "count = 10\n",
    "\n",
    "for i, path in enumerate(paths[:count]):\n",
    "    print('\\r%6.2f%% complete' % ((i+1)/count*100), end='', flush=True)\n",
    "    \n",
    "    replay = sc2reader.load_replay(path, engine=sc2reader.engine.GameEngine(plugins=[ContextLoader(), APMTracker(), SelectionTracker()]))\n",
    "    replays.append(replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "00.00\tSeither         ChatEvent\tmessage=\"glhf\"\n00.10\tProbe           ChatEvent\tmessage=\"gl hf\"\n14.28\tSeither         ChatEvent\tmessage=\"gg\"\nPlayer 1 - Seither (Terran) Loss\n"
     ]
    }
   ],
   "source": [
    "for event in replays[0].messages:\n",
    "    print('%s\\tmessage=\"%s\"' % (event, event.text))\n",
    "\n",
    "replays[0].players[0].name\n",
    "print(replays[0].players[0], replays[0].players[0].result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Marine', 'Colossus', 'Hellion', 'SiegeTankSieged', 'Disruptor', 'Starport', 'Marauder', 'Viking', 'Probe', 'Zealot', 'WarpPrismPhasing', 'OrbitalCommand', 'Sentry', 'Archon', 'Stalker', 'SCV'}\n{'Marine', 'Colossus', 'SiegeTankSieged', 'Disruptor', 'Phoenix', 'WarpPrism', 'SiegeTank', 'ObserverSiegeMode', 'Marauder', 'DarkTemplar', 'Viking', 'LiberatorAG', 'Ghost', 'OrbitalCommandFlying', 'Probe', 'Raven', 'WidowMineBurrowed', 'Medivac', 'WidowMine', 'Zealot', 'OrbitalCommand', 'Sentry', 'Archon', 'Stalker', 'SCV'}\n{'Marine', 'Hellion', 'SiegeTankSieged', 'Disruptor', 'Phoenix', 'Marauder', 'Cyclone', 'LiberatorAG', 'MULE', 'Probe', 'Reaper', 'WidowMineBurrowed', 'Medivac', 'Oracle', 'OrbitalCommand', 'Zealot', 'Sentry', 'Immortal', 'Stalker', 'SCV'}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "attrs_PlayerStatsEvent = ['frame','second','workers_active_count','minerals_collection_rate','vespene_collection_rate']\n",
    "# attrs_UnitPositionsEvent = ['ability_type']\n",
    "\n",
    "for i, replay in enumerate(replays[:2]):\n",
    "\t# print('\\r%6.2f%% complete' % ((i+1)/count*100), end='', flush=True)\n",
    "\n",
    "\tsuper_set = set()\n",
    "\n",
    "\td1 = {}\n",
    "\td2 = {}\n",
    "\t\n",
    "\tset_start = False\n",
    "\n",
    "\tfor event in replay.events:\n",
    "\n",
    "\t\tif event.second % 30 == 0:\n",
    "\n",
    "\t\t\t# every 10 seconds\n",
    "\t\t\tif isinstance(event, events.PlayerStatsEvent):\n",
    "\n",
    "\t\t\t\tis_player_1 = replay.players[1].pid == event.pid\n",
    "\t\t\t\tname = replay.players[is_player_1].name\n",
    "\t\t\t\trace = replay.players[is_player_1].pick_race[0]\n",
    "\t\t\t\twin = replay.players[is_player_1].result == 'Win'\n",
    "\n",
    "\t\t\t\tlower_bound = 0 if event.second == 0 else event.second-30\n",
    "\t\t\t\tap30s = sum(list(replay.players[is_player_1].aps.values())[lower_bound:event.second])\n",
    "\n",
    "\t\t\t\td['match_id'] = i\n",
    "\t\t\t\td['ap30s'] = ap30s\n",
    "\t\t\t\td['race'] = race\n",
    "\t\t\t\td['name'] = name\n",
    "\t\t\t\td['win'] = win\n",
    "\n",
    "\t\t\t\tfor attr in attrs_PlayerStatsEvent:\n",
    "\t\t\t\t\td[attr] = eval('event.' + attr)\n",
    "\t\t\t\t\n",
    "\t\t\t\tset_start = True\n",
    "\n",
    "\t\t\t# every 15 seconds\n",
    "\t\t\tif isinstance(event, events.UnitPositionsEvent):\n",
    "\t\t\t\tif set_start:\n",
    "\t\t\t\t\td['foobar'] = 'foobar'\n",
    "\t\t\t\t\tdata.append(d)\n",
    "\t\t\t\t\td = {}\n",
    "\n",
    "\t\t\t\t\ts = set([str(a).split(' ')[0] for a in event.units.keys()])\n",
    "\t\t\t\t\tsuper_set = super_set | s\n",
    "\n",
    "\t\t\t\t\tset_start = False\n",
    "\n",
    "\t\t\t\t# for attr in attrs_UnitPositionsEvent:\n",
    "\t\t\t\t# \td[attr] = eval('event.' + attr)\n",
    "\t\t\t\t# data.append(d)\n",
    "\n",
    "\tprint(super_set)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   match_id race     name  frame  second  workers_active_count  \\\n",
       "0         0    T  Seither      1       0                    12   \n",
       "1         0    P    Probe      1       0                    12   \n",
       "2         0    T  Seither    160      10                    12   \n",
       "3         0    P    Probe    160      10                    12   \n",
       "4         0    T  Seither    320      20                    13   \n",
       "\n",
       "   minerals_collection_rate  vespene_collection_rate  \n",
       "0                         0                        0  \n",
       "1                         0                        0  \n",
       "2                       293                        0  \n",
       "3                       209                        0  \n",
       "4                       671                        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match_id</th>\n      <th>race</th>\n      <th>name</th>\n      <th>frame</th>\n      <th>second</th>\n      <th>workers_active_count</th>\n      <th>minerals_collection_rate</th>\n      <th>vespene_collection_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>T</td>\n      <td>Seither</td>\n      <td>1</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>P</td>\n      <td>Probe</td>\n      <td>1</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>T</td>\n      <td>Seither</td>\n      <td>160</td>\n      <td>10</td>\n      <td>12</td>\n      <td>293</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>P</td>\n      <td>Probe</td>\n      <td>160</td>\n      <td>10</td>\n      <td>12</td>\n      <td>209</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>T</td>\n      <td>Seither</td>\n      <td>320</td>\n      <td>20</td>\n      <td>13</td>\n      <td>671</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['vespene_units', 'supply_units', 'worker_units', 'base_units', 'ground_units', 'air_units', 'tech_units', 'army_units', 'army_air', 'army_ground'])"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pieces.pickle', 'rb') as f:\n",
    "    pieces = pickle.load(f)\n",
    "\n",
    "pieces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-960ab1098a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreplay_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-130-5fefdebb5ba9>\u001b[0m in \u001b[0;36mparse_replay\u001b[0;34m(cls, replay, replay_file, file_object)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mreplay_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# This is the engine that holds some required plugins for parsing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-5fefdebb5ba9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, replay)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "replay_object = ReplayData.parse_replay(replay=replays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}